{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PyTorch MNIST_Valdivino Santiago.ipynb","provenance":[{"file_id":"https://github.com/AvivSham/Pytorch-MNIST-colab/blob/master/Pytorch_MNIST.ipynb","timestamp":1631641874508}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hFJ4A6-l8kwK"},"source":["## **Deep Learning**\n","\n","----\n","\n","**Author**:  <a href=\"https://www.linkedin.com/in/valdivino-alexandre-de-santiago-j%C3%BAnior-103109206/?locale=en_US\">Valdivino Alexandre de Santiago JÃºnior</a>\n","\n","\\\\\n","\n","**Licence**: GNU GENERAL PUBLIC LICENSE, Version 3 (GPLv3)\n","\n","\\\\\n","\n","This is a notebook for the handwritten digit classification problem based on the classical Modified National Institute of Standards and Technology (MNIST) database. It uses three neural networks to address this problem: ```SNN500``` by <a href=\"https://github.com/AvivSham/Pytorch-MNIST-colab\">Aviv Shamsian</a>, ```CNN3L``` by <a href=\"https://medium.com/@nutanbhogendrasharma/pytorch-convolutional-neural-network-with-mnist-dataset-4e8a4265e118\">Nutan</a>, and ```LeNet-5``` by <a href=\"https://github.com/bollakarthikeya/LeNet-5-PyTorch/blob/master/lenet5_gpu.py\">Bolla Karthikeya</a>. \n","\n","\n"]},{"cell_type":"code","metadata":{"cellView":"code","id":"bGU6NwlsXFSt"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","from prettytable import PrettyTable\n","import matplotlib.pyplot as plt\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vOp6EDP_2yU5"},"source":["# This function obtains the number of trainable parameters of the \n","# model/network.\n","def count_parameters(model):\n","    table = PrettyTable([\"Modules\", \"Parameters\"])\n","    total_params = 0\n","    for name, parameter in model.named_parameters():\n","        if not parameter.requires_grad: continue\n","        param = parameter.numel()\n","        table.add_row([name, param])\n","        total_params+=param\n","    print(table)\n","    print(f\"Total trainable params: {total_params}\")\n","    return total_params"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kOMpBMxWfCWu"},"source":["# Just visualising some images\n","def visualise_images(img, lab, t):\n","   fig = plt.figure()\n","   for i in range(6):\n","     plt.subplot(2,3,i+1)\n","     plt.tight_layout()\n","     plt.imshow(img[i][0], cmap='gray', interpolation='none')\n","     plt.title(\"{} - class: {}\".format(t,lab[i]))\n","     plt.xticks([])\n","     plt.yticks([])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MG0mBCsKj5Jv"},"source":["## **Define important variables**\n","----\n","\n","Here, we define the number of classes and also some hyper-parameters."]},{"cell_type":"code","metadata":{"cellView":"code","id":"_bNfVLRUYqZA"},"source":["num_classes = 10 # Number of output classes, discrete range [0,9]\n","\n","# Hyper-parameters\n","num_epochs = 10 # Number of epochs\n","batch_size = 100 # The size of input data took for one iteration\n","lr = 1e-3 # Learning rate"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_TypWsyHkQUQ"},"source":["## **MNIST dataset**\n","----\n","\n","Downloading and handling the MNIST dataset. Note that, as the PyTorch documentation, <a href=\"https://pytorch.org/vision/stable/transforms.html\">```transforms.ToTensor()```</a> \"converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8\"."]},{"cell_type":"code","metadata":{"cellView":"code","id":"lCsBCXMwbpH5"},"source":["# Downloading MNIST dataset\n","train_data = dsets.MNIST(root = './data', train = True,\n","                        transform = transforms.ToTensor(), download = True)\n","\n","test_data = dsets.MNIST(root = './data', train = False,\n","                       transform = transforms.ToTensor())\n","\n","print('#'*20)\n","print('Training dataset: ', train_data)\n","print('Test dataset: ', test_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"code","id":"rfDPBdnYgfGp"},"source":["# Wrap an iterable around the dataset to enable easy access to the samples.\n","train_gen = torch.utils.data.DataLoader(dataset = train_data,\n","                                        batch_size = batch_size,\n","                                        shuffle = True)\n","\n","test_gen = torch.utils.data.DataLoader(dataset = test_data,\n","                                       batch_size = batch_size, \n","                                       shuffle = False)\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print('Device is: ', device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-RFrcWLKG3kq"},"source":["## **Looking at the datasets**\n","\n","----\n","\n","Just taking a quick look at the datasets.\n","\n"]},{"cell_type":"code","metadata":{"id":"0UTIJs7PFhnZ"},"source":["batch_train = enumerate(train_gen)\n","batch_idx, (batch_train_data, batch_train_classes) = next(batch_train)\n","print('One batch - training dataset:', batch_train_data.shape)\n","\n","print('\\nEach image of the batch:')\n","for i in range(batch_train_classes.shape[0]):\n","  print('Image: {} - Input shape: {} - Class: {}'.format(i, batch_train_data[i].shape, batch_train_classes[i]))\n","  if i == (batch_train_classes.shape[0]-1):\n","    print('The \"image\" itself: ', batch_train_data[i])\n","\n","visualise_images(batch_train_data, batch_train_classes, 'Training')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LFBuAU2bgwpj"},"source":["batch_test = enumerate(test_gen)\n","batch_idx, (batch_test_data, batch_test_classes) = next(batch_test)\n","print('One batch - test dataset:', batch_test_data.shape)\n","\n","visualise_images(batch_test_data, batch_test_classes, 'Test' )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cWqmSTIo_yYv"},"source":["## **Neural networks**\n","\n","----\n","\n","We use three neural networks in order to compare their performances based on the accuracy of the test dataset. The first is ```SNN500``` which is a shallow neural network (SNN) with a single hidden layer containing 500 neurons (traditionally, a model/network is considered shallow when it has one or two hidden layers). \n","\n","<img src=\"https://scipython.com/static/media/uploads/blog/shallow-neural-net/snn.png\" width=\"300\"/>\n","\n","\\\\\n","\n","The second network is ```CNN3L``` which is also considered an SNN because it has two hidden (convolutional) layers and the output layer \n","\n","\\\\\n","\n","The third network is the classical <a href=\"https://ieeexplore.ieee.org/document/726791\">```LeNet-5```</a> DNN with five layers where four are hidden ones.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"cellView":"code","id":"fL-YXTvghaz_"},"source":["class SNN500(nn.Module):\n","  def __init__(self, input_sz, hidden_sz, num_clas):\n","    super(SNN500,self).__init__()\n","    self.fc1 = nn.Linear(input_sz, hidden_sz)\n","    self.relu = nn.ReLU()\n","    self.fc2 = nn.Linear(hidden_sz, num_clas)\n","  \n","  def forward(self,x):\n","    out = self.fc1(x)\n","    out = self.relu(out)\n","    out = self.fc2(out)\n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"78aQsuXG2HMl"},"source":["class CNN3L(nn.Module):\n","    def __init__(self, num_clas):\n","        super(CNN3L, self).__init__()\n","        self.conv1 = nn.Sequential(         \n","            nn.Conv2d(\n","                in_channels=1,              \n","                out_channels=16,            \n","                kernel_size=5,              \n","                stride=1,                   \n","                padding=2,                  \n","            ),                              \n","            nn.ReLU(),                      \n","            nn.MaxPool2d(kernel_size=2),    \n","        )\n","        self.conv2 = nn.Sequential(         \n","            nn.Conv2d(16, 32, 5, 1, 2),     \n","            nn.ReLU(),                      \n","            nn.MaxPool2d(kernel_size=2),                \n","        )\n","        # Fully-connected layer\n","        self.out = nn.Linear(32 * 7 * 7, num_clas)\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        # Flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n","        x = x.view(x.size(0), -1)       \n","        output = self.out(x)\n","        return output   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fzqclRyR-XPU"},"source":["class LeNet5(nn.Module):          \n","    def __init__(self, num_clas):     \n","        super(LeNet5, self).__init__()\n","        # Convolution \n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2, bias=True)\n","        # Max-pooling\n","        self.max_pool_1 = nn.MaxPool2d(kernel_size=2)\n","        # Convolution\n","        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)\n","        # Max-pooling\n","        self.max_pool_2 = nn.MaxPool2d(kernel_size=2) \n","        # Fully-connected layers\n","        self.fc1 = nn.Linear(16*5*5, 120)   # convert matrix with 16*5*5 (= 400) features to a matrix of 120 features (columns)\n","        self.fc2 = nn.Linear(120, 84)       # convert matrix with 120 features to a matrix of 84 features (columns)\n","        self.fc3 = nn.Linear(84, num_clas)        # convert matrix with 84 features to a matrix of 10 features (columns)\n","        \n","    def forward(self, x):\n","        # Convolve, then perform ReLU non-linearity\n","        x = nn.functional.relu(self.conv1(x))  \n","        # Max-pooling with 2x2 grid \n","        x = self.max_pool_1(x) \n","        # Convolve, then perform ReLU non-linearity\n","        x = nn.functional.relu(self.conv2(x))\n","        # Max-pooling with 2x2 grid\n","        x = self.max_pool_2(x)\n","        # First flatten 'max_pool_2_out' to contain 16*5*5 columns\n","        x = x.view(-1, 16*5*5)\n","        # FC-1, then perform ReLU non-linearity\n","        x = nn.functional.relu(self.fc1(x))\n","        # FC-2, then perform ReLU non-linearity\n","        x = nn.functional.relu(self.fc2(x))\n","        # FC-3\n","        x = self.fc3(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6DPf390KCQta"},"source":["## **Select the model**\n","\n","----\n","\n","Now, we can select one of the models/networks to train and evaluate."]},{"cell_type":"code","metadata":{"cellView":"code","id":"-3EPEqbjjfAT"},"source":["opt = input(\"Enter your choice:\")\n","if opt =='1':\n","  input_size = 784 # img_size = (28,28) ---> 28*28=784 in total\n","  hidden_size_tb = 500 # Number of nodes at hidden layer\n","  net = SNN500(input_size, hidden_size_tb, num_classes)\n","  opt_name = 'SNN500'\n","  print(\"You selected SNN500!\")\n","elif opt =='2':\n","  net = CNN3L(num_classes)\n","  opt_name = 'CNN3L'\n","  print(\"You selected CNN3L!\")\n","elif opt =='3':\n","  net = LeNet5(num_classes)\n","  opt_name = 'LeNet-5'\n","  print(\"You selected LeNet-5!\")\n","else:\n","  print(\"Invalid Option!\")\n","\n","if torch.cuda.is_available():\n","   net.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"syNIW-CMChqO"},"source":["## **Define loss function and optimiser**\n","\n","----\n","\n","The <a href=\"https://github.com/AvivSham/Pytorch-MNIST-colab\">CrossEntropyLoss</a> function combines LogSoftmax and NLLLoss in one single class. The learning rate has already been defined."]},{"cell_type":"code","metadata":{"cellView":"code","id":"ePLIwvAFj2zH"},"source":["loss_function = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","\n","print('Checking trainable parameters: {}'.format(count_parameters(net)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-9_YTPhfCzkk"},"source":["## **Training phase**\n","\n","----\n","\n","Now, we can train the model."]},{"cell_type":"code","metadata":{"cellView":"code","id":"u75Xa5VckuTH"},"source":["current_time = time.time()\n","train_losses = []\n","train_acc = []\n","for epoch in range(num_epochs):\n","  net.train() \n","  running_loss = 0.0\n","  running_corrects = 0\n","  for images,labels in train_gen: # Iterate over data: begin\n","    if opt == '1':\n","      images = Variable(images.view(-1,28*28)).to(device) # Send to GPU\n","    elif (opt == '2') or (opt == '3'):\n","      images = Variable(images).to(device) # Send to GPU\n","    \n","    labels = Variable(labels).to(device) # Send to GPU\n","    optimizer.zero_grad()\n","    with torch.set_grad_enabled(True):\n","        outputs = net(images)\n","        _, preds = torch.max(outputs, 1)\n","        loss = loss_function(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    \n","    running_loss += loss.item() * images.size(0)\n","    running_corrects += torch.sum(preds == labels.data)\n","  # Iterate over data: end\n","\n","  epoch_loss = running_loss / len(train_data)\n","  epoch_acc = running_corrects.double() / len(train_data)  \n","  print('Epoch [%d/%d], Loss: %.4f, Accuracy: %.4f'\n","                 %(epoch+1, num_epochs, epoch_loss, epoch_acc))\n","  \n","  train_losses.append(epoch_loss)\n","  train_acc.append(epoch_acc)    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wEeJ-PJ30NqB"},"source":["## **Training phase: results**\n","----\n","\n","Just showing the loss and accuracy during the training phase.\n","\n"]},{"cell_type":"code","metadata":{"id":"c_5ga_XT1CG8"},"source":["x = range(1,len(train_losses)+1)\n","\n","plt.figure(figsize=(8,4))\n","plt.title(\"Training Phase\")\n","plt.plot(x,train_losses,label=\"Loss\")\n","plt.plot(x,train_acc,label=\"Acc\")\n","plt.xticks(range(1,len(x)+1))\n","plt.xlabel(\"Epochs\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lik5ZBN1C_fz"},"source":["## **Inference phase**\n","\n","----\n","\n","In the inference phase, we measure the performance of our model. "]},{"cell_type":"code","metadata":{"cellView":"code","id":"DTPvMW5jHB9X"},"source":["am_training = net.training\n","print('Am I training? ', am_training)\n","net.eval()\n","am_training = net.training\n","print('Am I training? ', am_training)\n","inference_loss = 0.0\n","inference_corrects = 0\n","\n","with torch.no_grad():\n","  for images,labels in test_gen: # Iterate over data: begin\n","      if opt == '1':\n","        images = Variable(images.view(-1,28*28)).to(device) # Send to GPU\n","      elif opt == '2' or opt == '3':\n","        images = Variable(images).to(device) # Send to GPU\n","      \n","      labels = labels.to(device) # Send to GPU\n","      outputs_infer = net(images)\n","      _, preds_infer = torch.max(outputs_infer,1)\n","      loss_infer = loss_function(outputs_infer, labels)\n","\n","      inference_loss += loss_infer.item() * images.size(0)\n","      inference_corrects += torch.sum(preds_infer == labels.data)\n","  # Iterate over data: end\n","\n","final_inference_loss = inference_loss / len(test_data)\n","final_inference_acc = inference_corrects.double() / len(test_data)\n","\n","time_elapsed = time.time() - current_time\n","print('\\nTraining and inference in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","\n","print('\\nLoss of {}: {:.4f}'.format(opt_name, final_inference_loss))\n","print()\n","print('Accuracy of {}: {:.4f}'.format(opt_name, final_inference_acc))"],"execution_count":null,"outputs":[]}]}