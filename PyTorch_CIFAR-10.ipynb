{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"colab":{"name":"PyTorch CIFAR-10_Valdivino SantiagoV2.ipynb","provenance":[{"file_id":"https://github.com/pytorch/tutorials/blob/gh-pages/_downloads/17a7c7cb80916fcdf921097825a0f562/cifar10_tutorial.ipynb","timestamp":1631832330553}],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"L2OH5wBkyRLr"},"source":["## **Deep Learning**\n","\n","----\n","\n","Author:  <a href=\"https://www.linkedin.com/in/valdivino-alexandre-de-santiago-j%C3%BAnior-103109206/?locale=en_US\">Valdivino Alexandre de Santiago JÃºnior</a>.\n","\n","\n","\\\\\n","\n","**Licence**: GNU GENERAL PUBLIC LICENSE, Version 3 (GPLv3)\n","\n","\\\\\n","\n","This is a notebook for the image classification problem based on the classical CIFAR-10 database. It is a modification of the <a href=\"https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\">*Training a Classifier*</a> PyTorch tutorial. It uses two neural networks to address this problem: ```CNN3L``` by <a href=\"https://medium.com/@nutanbhogendrasharma/pytorch-convolutional-neural-network-with-mnist-dataset-4e8a4265e118\">Nutan</a> and ```LeNet-5``` presented in the *Training a Classifier* tutorial.  \n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"zx2nVrVHyRLo"},"source":["%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BYyU_vknyRLt"},"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import time\n","from torch.autograd import Variable\n","from prettytable import PrettyTable"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"15m70lWTGRKL"},"source":["# This function obtains the number of trainable parameters of the \n","# model/network.\n","def count_parameters(model):\n","    table = PrettyTable([\"Modules\", \"Parameters\"])\n","    total_params = 0\n","    for name, parameter in model.named_parameters():\n","        if not parameter.requires_grad: continue\n","        param = parameter.numel()\n","        table.add_row([name, param])\n","        total_params+=param\n","    print(table)\n","    print(f\"Total trainable params: {total_params}\")\n","    return total_params"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2DwXV-hcB92e"},"source":["## **Define important variables**\n","----\n","\n","Here, we define the classes and also some hyper-parameters."]},{"cell_type":"code","metadata":{"id":"GZTAYscZCBBU"},"source":["classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","num_classes = len(classes)\n","\n","# Hyper-parameters\n","num_epochs = 10 # Number of epochs\n","batch_size = 4 # The size of input data took for one iteration\n","lr = 1e-3 # Learning rate"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M2zkn9dXyRLt"},"source":["## **CIFAR-10 dataset**\n","----\n","\n","Downloading and handling the CIFAR-10 dataset. As per the PyTorch tutorial, \"the output of torchvision datasets are PILImage images of range [0, 1]. We transform them to tensors of normalized range [-1, 1].\" This normalisation is done by ```transforms.Normalize```.\n","\n"]},{"cell_type":"code","metadata":{"id":"qOixbGxyyRLu"},"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=2)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print('Device is: ', device)\n","\n","print('#'*20)\n","print('Training dataset: ', trainset)\n","print('Test dataset: ', testset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k1Hi2bkLyRLv"},"source":["## **Looking at the training dataset**\n","\n","----\n","\n","Just taking a quick look at the training dataset.\n","\n"]},{"cell_type":"code","metadata":{"id":"DL53jmeFyRLv"},"source":["# Just visualising some images\n","def visualise_images(img):\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.show()\n","\n","\n","# Get a batch: training dataset\n","dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n","print('One batch - training dataset:', images.shape)\n","\n","print('\\nEach image of the batch:')\n","for i in range(labels.shape[0]):\n","  print('Image: {} - Input shape: {} - Class: {}'.format(i, images[i].shape, labels[i]))\n","  if i == (labels.shape[0]-1):\n","    print('The \"image\" itself: ', images[i])\n","\n","# Show images\n","visualise_images(torchvision.utils.make_grid(images))\n","# Print labels\n","print(' - '.join('%5s' % classes[labels[j]] for j in range(batch_size)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MxZ5R2fFyRLw"},"source":["## **Neural networks**\n","\n","----\n","\n","We use two neural networks in order to compare their performances based on the accuracy of the test dataset. The first network is ```CNN3L``` which is considered a shallow neural network (SNN) because it has two hidden (convolutional) layers and the output layer (traditionally, a model/network is considered shallow when it has one or two hidden layers).\n","\n","\\\\\n","\n","The second network is the classical <a href=\"https://ieeexplore.ieee.org/document/726791\">```LeNet-5```</a> DNN with five layers where four are hidden ones.\n","\n"]},{"cell_type":"code","metadata":{"id":"O6yY2CpEV5Fv"},"source":["class CNN3L(nn.Module):\n","    def __init__(self, num_clas):\n","        super(CNN3L, self).__init__()\n","        self.conv1 = nn.Sequential(         \n","            nn.Conv2d(\n","                in_channels=3,              \n","                out_channels=16,            \n","                kernel_size=5,              \n","                stride=1,                   \n","                padding=0,                  \n","            ),                              \n","            nn.ReLU(),                      \n","            nn.MaxPool2d(kernel_size=2),    \n","        )\n","        self.conv2 = nn.Sequential(         \n","            nn.Conv2d(16, 32, 5, 1, 0),     \n","            nn.ReLU(),                      \n","            nn.MaxPool2d(kernel_size=2),                \n","        )\n","        # Fully-connected layer\n","        self.out = nn.Linear(32 * 5 * 5, num_clas)\n","    def forward(self, x):\n","        #print('x size 0: ', x.size())\n","        x = self.conv1(x)\n","        #print('x size 1: ', x.size())\n","        x = self.conv2(x)\n","        #print('x size 2: ', x.size())\n","        x = x.view(x.size(0), -1) \n","        #print('x size 3: ', x.size())\n","        output = self.out(x)\n","        #print('output: ', output.size())\n","        return output   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3avaW5rcyRLw"},"source":["class LeNet5(nn.Module):\n","    def __init__(self, num_clas):\n","        super(LeNet5,self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0, bias=True)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, num_clas)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = torch.flatten(x, 1) # flatten all dimensions except batch\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UXD48sAEyRLx"},"source":["## **Select the model**\n","\n","----\n","\n","Now, we can select one of the models/networks to train and evaluate.\n","\n"]},{"cell_type":"code","metadata":{"id":"AxH16D71CkbA"},"source":["opt = input(\"Enter your choice:\")\n","if opt =='1':\n","  net = CNN3L(num_classes)\n","  opt_name = 'CNN3L'\n","  print(\"You selected CNN3L!\")\n","elif opt =='2':\n","  net = LeNet5(num_classes)\n","  opt_name = 'LeNet-5'\n","  print(\"You selected LeNet-5!\")\n","else:\n","  print(\"Invalid Option!\")\n","\n","if torch.cuda.is_available():\n","   net.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F-ruktCEESD7"},"source":["## **Define loss function and optimiser**\n","\n","----\n","\n","The <a href=\"https://github.com/AvivSham/Pytorch-MNIST-colab\">CrossEntropyLoss</a> function combines LogSoftmax and NLLLoss in one single class. The learning rate has already been defined."]},{"cell_type":"code","metadata":{"id":"xwmn5SgPyRLx"},"source":["loss_function = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=lr)\n","\n","print('Checking trainable parameters: {}'.format(count_parameters(net)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kP6qAZZWyRLx"},"source":["## **Training phase**\n","\n","----\n","\n","Now, we can train the model.\n","\n"]},{"cell_type":"code","metadata":{"id":"PZJ0tn5pCNmR"},"source":["train_losses = []\n","train_acc = []\n","train_time_init = time.time()\n","for epoch in range(num_epochs):\n","  net.train() \n","  running_loss = 0.0\n","  running_corrects = 0\n","  for images,labels in trainloader: # Iterate over data: begin\n","    images = Variable(images).to(device) # Send to GPU\n","    labels = Variable(labels).to(device) # Send to GPU\n","    \n","    optimizer.zero_grad()\n","    with torch.set_grad_enabled(True):\n","        outputs = net(images)\n","        _, preds = torch.max(outputs, 1)\n","        loss = loss_function(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","    \n","    running_loss += loss.item() * images.size(0)\n","    running_corrects += torch.sum(preds == labels.data)\n","  # Iterate over data: end\n","\n","  epoch_loss = running_loss / len(trainset)\n","  epoch_acc = running_corrects.double() / len(trainset)  \n","  print('Epoch [%d/%d], Loss: %.4f, Accuracy: %.4f'\n","                 %(epoch+1, num_epochs, epoch_loss, epoch_acc))\n","  \n","  train_losses.append(epoch_loss)\n","  train_acc.append(epoch_acc) \n","\n","train_time_end = time.time() - train_time_init     "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pz_imGtqyRLy"},"source":["## **Save the best model**\n","----\n","\n","You can save your best model to use later in the inference phase (here it is truly the model after the last epoch). \n","\n"]},{"cell_type":"code","metadata":{"id":"pQerb9SnyRLy"},"source":["best = './cifar10_net.pt'\n","torch.save(net.state_dict(), best)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c45S9CzqJ6br"},"source":["## **Training phase: results**\n","----\n","\n","Just showing the loss and accuracy during the training phase."]},{"cell_type":"code","metadata":{"id":"Jm7R-vzVJ9sI"},"source":["x = range(1,len(train_losses)+1)\n","\n","plt.figure(figsize=(8,4))\n","plt.title(\"Training Phase\")\n","plt.plot(x,train_losses,label=\"Loss\")\n","plt.plot(x,train_acc,label=\"Acc\")\n","plt.xticks(range(1,len(x)+1))\n","plt.xlabel(\"Epochs\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JcC7RfzfyRLy"},"source":["## **Looking at the test dataset**\n","\n","----\n","\n","Just taking a quick look at the test dataset.\n","\n"]},{"cell_type":"code","metadata":{"id":"LhcA3_Z9yRLz"},"source":["dataiter = iter(testloader)\n","images, labels = dataiter.next()\n","print('One batch - test dataset:', images.shape)\n","\n","# Show some images\n","visualise_images(torchvision.utils.make_grid(images))\n","# Print labels\n","print(' - '.join('%5s' % classes[labels[j]] for j in range(4)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EwmERrX8yRLz"},"source":["## **Load the model**\n","----\n","\n","You can load your best model to use in the inference phase. \n","\n"]},{"cell_type":"code","metadata":{"id":"k0vhDYSryRLz"},"source":["if opt =='1':\n","  net = CNN3L(num_classes)\n","  print(\"Best CNN3L model loaded!\")\n","elif opt =='2':\n","  net = LeNet5(num_classes)\n","  print(\"Best LeNet-5 model loaded!\")\n","else:\n","  print(\"Invalid Option!\")\n","\n","if torch.cuda.is_available():\n","   net.to(device)\n","net.load_state_dict(torch.load(best))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QY9I0yBpyRL0"},"source":["## **Inference phase**\n","\n","----\n","\n","In the inference phase, we measure the performance of our model. \n","\n"]},{"cell_type":"code","metadata":{"id":"pnnbNqQuyRL0"},"source":["am_training = net.training\n","print('Am I training? ', am_training)\n","net.eval()\n","am_training = net.training\n","print('Am I training? ', am_training)\n","inference_loss = 0.0\n","inference_corrects = 0\n","\n","infer_time_init = time.time()\n","with torch.no_grad():\n","  for images,labels in testloader: # Iterate over data: begin\n","      images = Variable(images).to(device) # Send to GPU\n","      labels = labels.to(device) # Send to GPU\n","\n","      outputs_infer = net(images)\n","      _, preds_infer = torch.max(outputs_infer,1)\n","      loss_infer = loss_function(outputs_infer, labels)\n","\n","      inference_loss += loss_infer.item() * images.size(0)\n","      inference_corrects += torch.sum(preds_infer == labels.data)\n","  # Iterate over data: end\n","\n","final_inference_loss = inference_loss / len(testset)\n","final_inference_acc = inference_corrects.double() / len(testset)\n","\n","infer_time_end = time.time() - infer_time_init\n","print('\\nTraining and inference in {:.0f}m {:.0f}s  OR  {:.0f}s'.format(\n","        (train_time_end + infer_time_end) // 60, \n","        (train_time_end + infer_time_end) % 60,\n","         train_time_end + infer_time_end))\n","\n","print('\\nLoss of {}: {:.4f}'.format(opt_name, final_inference_loss))\n","print()\n","print('Accuracy of {}: {:.4f}'.format(opt_name, final_inference_acc))"],"execution_count":null,"outputs":[]}]}