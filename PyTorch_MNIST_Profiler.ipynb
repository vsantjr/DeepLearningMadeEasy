{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PyTorch MNIST_Valdivino Santiago_Profiler.ipynb","provenance":[{"file_id":"https://github.com/AvivSham/Pytorch-MNIST-colab/blob/master/Pytorch_MNIST.ipynb","timestamp":1631641874508}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hFJ4A6-l8kwK"},"source":["## **Deep Learning**\n","\n","----\n","\n","**Author**:  <a href=\"https://www.linkedin.com/in/valdivino-alexandre-de-santiago-j%C3%BAnior-103109206/?locale=en_US\">Valdivino Alexandre de Santiago JÃºnior</a>\n","\n","\\\\\n","\n","**Licence**: GNU GENERAL PUBLIC LICENSE, Version 3 (GPLv3)\n","\n","\\\\\n","\n","This notebook is related to the handwritten digit classification problem based on the classical Modified National Institute of Standards and Technology (MNIST) database. Hovewer, its goal is to address performance bottlenecks of the network/model via the TensorBoard Plugin with PyTorch Profiler. Hence, it will not cover the classification task completely. It uses three neural networks: ```SNN500``` by <a href=\"https://github.com/AvivSham/Pytorch-MNIST-colab\">Aviv Shamsian</a>, ```CNN3L``` by <a href=\"https://medium.com/@nutanbhogendrasharma/pytorch-convolutional-neural-network-with-mnist-dataset-4e8a4265e118\">Nutan</a>, and ```LeNet-5``` by <a href=\"https://github.com/bollakarthikeya/LeNet-5-PyTorch/blob/master/lenet5_gpu.py\">Bolla Karthikeya</a>. \n","\n","\n"]},{"cell_type":"code","metadata":{"cellView":"code","id":"bGU6NwlsXFSt"},"source":["import torch\n","import torch.nn as nn\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","from prettytable import PrettyTable\n","import matplotlib.pyplot as plt\n","import time\n","import torch.profiler\n","import torch.utils.data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vOp6EDP_2yU5"},"source":["# This function obtains the number of trainable parameters of the \n","# model/network.\n","def count_parameters(model):\n","    table = PrettyTable([\"Modules\", \"Parameters\"])\n","    total_params = 0\n","    for name, parameter in model.named_parameters():\n","        if not parameter.requires_grad: continue\n","        param = parameter.numel()\n","        table.add_row([name, param])\n","        total_params+=param\n","    print(table)\n","    print(f\"Total trainable params: {total_params}\")\n","    return total_params"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kOMpBMxWfCWu"},"source":["# Just visualising some images\n","def visualise_images(img, lab, t):\n","   fig = plt.figure()\n","   for i in range(6):\n","     plt.subplot(2,3,i+1)\n","     plt.tight_layout()\n","     plt.imshow(img[i][0], cmap='gray', interpolation='none')\n","     plt.title(\"{} - class: {}\".format(t,lab[i]))\n","     plt.xticks([])\n","     plt.yticks([])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MG0mBCsKj5Jv"},"source":["## **Define important variables**\n","----\n","\n","Here, we define the number of classes, some hyper-parameters, and the number of images of the training dataset to consider in the performance analysis."]},{"cell_type":"code","metadata":{"cellView":"code","id":"_bNfVLRUYqZA"},"source":["num_classes = 10 # Number of output classes, discrete range [0,9]\n","\n","# Hyper-parameters\n","batch_size = 100 # The size of input data took for one iteration\n","lr = 1e-3 # Learning rate\n","\n","# Number of images: profiling\n","num_images = 10000 # Number of images to consider\n","max_batches = num_images/batch_size # Maximum number of batches\n","print('Maximum number of batches: ', int(max_batches))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_TypWsyHkQUQ"},"source":["## **MNIST dataset**\n","----\n","\n","Downloading and handling the MNIST dataset. Note that, as the PyTorch documentation, <a href=\"https://pytorch.org/vision/stable/transforms.html\">```transforms.ToTensor()```</a> \"converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8\"."]},{"cell_type":"code","metadata":{"cellView":"code","id":"lCsBCXMwbpH5"},"source":["# Downloading MNIST dataset. We only need the training dataset in this analysis.\n","train_data = dsets.MNIST(root = './data', train = True,\n","                        transform = transforms.ToTensor(), download = True)\n","\n","print('#'*20)\n","print('Training dataset: ', train_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"code","id":"rfDPBdnYgfGp"},"source":["# Wrap an iterable around the dataset to enable easy access to the samples.\n","train_loader = torch.utils.data.DataLoader(dataset = train_data,\n","                                        batch_size = batch_size,\n","                                        shuffle = True)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print('Device is: ', device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-RFrcWLKG3kq"},"source":["## **Looking at the training dataset**\n","\n","----\n","\n","Just taking a quick look at the training dataset.\n","\n"]},{"cell_type":"code","metadata":{"id":"0UTIJs7PFhnZ"},"source":["batch_train = enumerate(train_loader)\n","batch_idx, (batch_train_data, batch_train_classes) = next(batch_train)\n","print('One batch - training dataset:', batch_train_data.shape)\n","\n","print('\\nEach image of the batch:')\n","for i in range(batch_train_classes.shape[0]):\n","  print('Image: {} - Input shape: {} - Class: {}'.format(i, batch_train_data[i].shape, batch_train_classes[i]))\n","  if i == (batch_train_classes.shape[0]-1):\n","    print('The \"image\" itself: ', batch_train_data[i])\n","\n","visualise_images(batch_train_data, batch_train_classes, 'Training')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cWqmSTIo_yYv"},"source":["## **Neural networks**\n","\n","----\n","\n","We use three neural networks in this analysis. The first is ```SNN500``` which is a shallow neural network (SNN) with a single hidden layer containing 500 neurons (traditionally, a model/network is considered shallow when it has one or two hidden layers). \n","\n","<img src=\"https://scipython.com/static/media/uploads/blog/shallow-neural-net/snn.png\" width=\"300\"/>\n","\n","\\\\\n","\n","The second network is ```CNN3L``` which is also considered an SNN because it has two hidden (convolutional) layers and the output layer \n","\n","\\\\\n","\n","The third network is the classical <a href=\"https://ieeexplore.ieee.org/document/726791\">```LeNet-5```</a> DNN with five layers where four are hidden ones.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"cellView":"code","id":"fL-YXTvghaz_"},"source":["class SNN500(nn.Module):\n","  def __init__(self, input_sz, hidden_sz, num_clas):\n","    super(SNN500,self).__init__()\n","    self.fc1 = nn.Linear(input_sz, hidden_sz)\n","    self.relu = nn.ReLU()\n","    self.fc2 = nn.Linear(hidden_sz, num_clas)\n","  \n","  def forward(self,x):\n","    out = self.fc1(x)\n","    out = self.relu(out)\n","    out = self.fc2(out)\n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"78aQsuXG2HMl"},"source":["class CNN3L(nn.Module):\n","    def __init__(self, num_clas):\n","        super(CNN3L, self).__init__()\n","        self.conv1 = nn.Sequential(         \n","            nn.Conv2d(\n","                in_channels=1,              \n","                out_channels=16,            \n","                kernel_size=5,              \n","                stride=1,                   \n","                padding=2,                  \n","            ),                              \n","            nn.ReLU(),                      \n","            nn.MaxPool2d(kernel_size=2),    \n","        )\n","        self.conv2 = nn.Sequential(         \n","            nn.Conv2d(16, 32, 5, 1, 2),     \n","            nn.ReLU(),                      \n","            nn.MaxPool2d(kernel_size=2),                \n","        )\n","        # Fully-connected layer\n","        self.out = nn.Linear(32 * 7 * 7, num_clas)\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        # Flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n","        x = x.view(x.size(0), -1)       \n","        output = self.out(x)\n","        return output   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fzqclRyR-XPU"},"source":["class LeNet5(nn.Module):          \n","    def __init__(self, num_clas):     \n","        super(LeNet5, self).__init__()\n","        # Convolution \n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2, bias=True)\n","        # Max-pooling\n","        self.max_pool_1 = nn.MaxPool2d(kernel_size=2)\n","        # Convolution\n","        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)\n","        # Max-pooling\n","        self.max_pool_2 = nn.MaxPool2d(kernel_size=2) \n","        # Fully-connected layers\n","        self.fc1 = nn.Linear(16*5*5, 120)   # convert matrix with 16*5*5 (= 400) features to a matrix of 120 features (columns)\n","        self.fc2 = nn.Linear(120, 84)       # convert matrix with 120 features to a matrix of 84 features (columns)\n","        self.fc3 = nn.Linear(84, num_clas)        # convert matrix with 84 features to a matrix of 10 features (columns)\n","        \n","    def forward(self, x):\n","        # Convolve, then perform ReLU non-linearity\n","        x = nn.functional.relu(self.conv1(x))  \n","        # Max-pooling with 2x2 grid \n","        x = self.max_pool_1(x) \n","        # Convolve, then perform ReLU non-linearity\n","        x = nn.functional.relu(self.conv2(x))\n","        # Max-pooling with 2x2 grid\n","        x = self.max_pool_2(x)\n","        # First flatten 'max_pool_2_out' to contain 16*5*5 columns\n","        x = x.view(-1, 16*5*5)\n","        # FC-1, then perform ReLU non-linearity\n","        x = nn.functional.relu(self.fc1(x))\n","        # FC-2, then perform ReLU non-linearity\n","        x = nn.functional.relu(self.fc2(x))\n","        # FC-3\n","        x = self.fc3(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6DPf390KCQta"},"source":["## **Select the model**\n","\n","----\n","\n","Now, we can select one of the models/networks."]},{"cell_type":"code","metadata":{"cellView":"code","id":"-3EPEqbjjfAT"},"source":["opt = input(\"Enter your choice:\")\n","if opt =='1':\n","  input_size = 784 # img_size = (28,28) ---> 28*28=784 in total\n","  hidden_size_tb = 500 # Number of nodes at hidden layer\n","  net = SNN500(input_size, hidden_size_tb, num_classes)\n","  opt_name = 'SNN500'\n","  print(\"You selected SNN500!\")\n","elif opt =='2':\n","  net = CNN3L(num_classes)\n","  opt_name = 'CNN3L'\n","  print(\"You selected CNN3L!\")\n","elif opt =='3':\n","  net = LeNet5(num_classes)\n","  opt_name = 'LeNet-5'\n","  print(\"You selected LeNet-5!\")\n","else:\n","  print(\"Invalid Option!\")\n","\n","if torch.cuda.is_available():\n","   net.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"syNIW-CMChqO"},"source":["## **Define loss function and optimiser**\n","\n","----\n","\n","The <a href=\"https://github.com/AvivSham/Pytorch-MNIST-colab\">CrossEntropyLoss</a> function combines LogSoftmax and NLLLoss in one single class. The learning rate has already been defined."]},{"cell_type":"code","metadata":{"cellView":"code","id":"ePLIwvAFj2zH"},"source":["loss_function = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n","\n","print('Checking trainable parameters: {}'.format(count_parameters(net)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-9_YTPhfCzkk"},"source":["## **Training phase**\n","\n","----\n","\n","Here, we starting training the model (```net.train()``` and function ```train_model(data)```)."]},{"cell_type":"code","metadata":{"id":"s4sqav0i78RG"},"source":["net.train() \n","def train_model(data):\n","  if opt == '1':\n","    images, labels = Variable(data[0].view(-1,28*28)).to(device), Variable(data[1]).to(device)\n","  elif (opt == '2') or (opt == '3'):\n","    images, labels = Variable(data[0]).to(device), Variable(data[1]).to(device) \n","      \n","  optimizer.zero_grad()\n","  with torch.set_grad_enabled(True):\n","    outputs = net(images)\n","    _, preds = torch.max(outputs, 1)\n","    loss = loss_function(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HJoq5eWj3EvI"},"source":["## **Use the PyTorch Profiler**\n","----\n","\n","Here, we use the PyTorch Profiler to record execution events. After running this notebook, the results will be saved under ```./log/xyz``` folder."]},{"cell_type":"code","metadata":{"id":"5j-I77pL8AEz"},"source":["with torch.profiler.profile(\n","        schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n","        on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/mnist_'+opt_name+'_bat_'+str(batch_size)),\n","        record_shapes=True,\n","        with_stack=True\n",") as prof:\n","    for num_batch, batch_data in enumerate(train_loader):\n","        print('Batch number:', num_batch)\n","        if num_batch >= int(max_batches): \n","            break\n","        train_model(batch_data)\n","        prof.step()  # Need to call this at the end of each step to notify profiler of steps' boundary."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A7fOQmQO3wT6"},"source":["## **Run TensorBoard**\n","----\n","\n","In order to visualise the results and check the performance bottlenecks of the model, proceed as follows as per the <a href=\"https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html\">PyTorch tutorial </a>:\n","\n","\n","\n","1. download the results in ```./log/xyz``` to your computer; \n","2. install PyTorch Profiler TensorBoard Plugin (```pip install torch_tb_profiler```);\n","3. launch the TensorBoard (```tensorboard --logdir=./log```);\n","4. open the TensorBoard profile URL in Google Chrome browser (```http://localhost:6006/#pytorch_profiler```). \n","\n","\n","\n"]}]}